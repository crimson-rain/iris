//! LLMCharacter Node used to create characters which can interact with ollama API.
//! This is the main way we use llms to interact with NPCs.
#![deny(clippy::todo)]

use std::thread;

use crate::llm::LLM;
use crate::memory::MemoryStore;
use crate::utils::parse_json::parse_json;
use godot::builtin::GString;
use godot::classes::{CharacterBody2D, ICharacterBody2D};
use godot::global::godot_print;
use godot::obj::Base;
use godot::prelude::{godot_api, GodotClass};
use ollama_rs::generation::chat::ChatMessage;
use tokio::runtime::Runtime;
use tokio::sync::mpsc;
use tokio::sync::mpsc::{Receiver, Sender};

/// Used to instantiate the LLMCharacter for Godot
///
/// ### Fields
/// ---
/// #### Godot Fields
/// - `id` - A GString that stores the ID, can be the name of the NPC itself.
/// - `profession`  -   A GString storing the NPC’s role and job.
/// - `description` -   A GString which stores the general description of the NPC,
///                     describing the general characteristics.
///
/// - `base`        -   ... TODO: Complete this fields documentation.
/// ---
/// #### System Fields
/// - `memory_store` -  Stores NPC memories using a hashtable where each entry has a unique memory ID
///                     and a `Memory` struct containing relevant details.
/// - `history`      -  Stores the NPC’s chat history for longer, context-aware conversations.
/// - `generation_channels` - API calls are asynchronous, thus we need to use channels to allow us to receive and send mutable data,
///                           from one thread to another.
#[derive(GodotClass)]
#[class(base=CharacterBody2D)]
struct LLMCharacter {
    #[export]
    id: GString,
    #[export]
    profession: GString,
    #[export(multiline)]
    description: GString,

    base: Base<CharacterBody2D>,
    memory_store: MemoryStore,
    history: Vec<ChatMessage>,
    generation_channels: GenerationChannels,
}

/// Generation Channels are used to send and receive data from different threads.
///
/// ### Fields
/// `dialogue_sender`   -   An optional sender that transmits dialogue responses between threads.
/// `dialogue_receiver` -   An optional receiver that collects dialogue responses from another thread.
struct GenerationChannels {
    dialogue_sender: Option<Sender<String>>,
    dialogue_receiver: Option<Receiver<String>>,
}

/// Uses the Factory Pattern to create default generation channels.
///
/// TODO: Abstract this for more customizability.
impl Default for GenerationChannels {
    fn default() -> Self {
        let (sender, receiver) = mpsc::channel(3);

        GenerationChannels {
            dialogue_sender: Some(sender),
            dialogue_receiver: Some(receiver),
        }
    }
}

/// Implement ICharacterBody2D which allows us to have access to Godot functions.
#[godot_api]
impl ICharacterBody2D for LLMCharacter {
    /// Initializes an `LLMCharacter` instance with default values.
    fn init(base: Base<CharacterBody2D>) -> Self {
        LLMCharacter {
            id: GString::new(),
            profession: GString::new(),
            description: GString::new(),
            base,
            memory_store: MemoryStore::default(),
            history: Vec::new(),
            generation_channels: GenerationChannels::default(),
        }
    }

    fn process(&mut self, _delta: f64) {
        self.process_generated_dialogue();
    }
}

#[godot_api]
impl LLMCharacter {
    /// Handles incoming dialogue responses generated by the LLM via the receiver channel.
    fn process_generated_dialogue(&mut self) {
        if let Some(receiver) = &mut self.generation_channels.dialogue_receiver {
            while let Ok(response) = receiver.try_recv() {
                let parsed_response = parse_json(response.as_str()).unwrap();
                godot_print!("{}", parsed_response)
            }
        }
    }

    /// TODO: Optimize this function to reduce redundant cloning and improve performance.
    #[func]
    fn request_dialogue_generation(&mut self) {
        let mut llm = LLM::default();

        let prompt = "How is your day?";
        let npc_info = self.get_npc_info();
        let combined_prompt = format!("Character Info: {}, Prompt: {}", npc_info, prompt);

        let mut history = self.history.clone();

        let sender = self.generation_channels.dialogue_sender.clone();
        let mut retrieve_memory = self.memory_store.retrieve_recent(3).clone();

        // Spawns a new thread to handle dialogue generation asynchronously,
        // preventing the main thread from blocking.
        thread::spawn(move || {
            let runtime = Runtime::new().expect("Failed to Create Runtime");

            runtime.block_on(async move {
                if let Ok(response) = llm
                    .generate_dialogue(combined_prompt.as_str(), &mut history, &mut retrieve_memory)
                    .await
                {
                    if let Some(sender) = sender {
                        let _ = sender.send(response.message.content).await;
                    }
                }
            });
        });
    }

    /// Get the NPC Information
    fn get_npc_info(&self) -> String {
        format!(
            "You are role-playing as the following NPC:\n\
              Name: {}\n\
              Profession: {}\n\
              Description: {}\n\
              Please respond in character to the player's inquiries.",
            self.id, self.profession, self.description
        )
    }

    #[signal]
    fn dialogue_generated(&self, response: GString);
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_response_channels() {
        let mut channels = GenerationChannels::default();

        if let Some(sender) = &channels.dialogue_sender {
            sender.send("Test Message".to_string()).await.unwrap();
        }

        if let Some(receiver) = &mut channels.dialogue_receiver {
            assert_eq!(receiver.try_recv().unwrap(), "Test Message".to_string());
        }
    }
}
